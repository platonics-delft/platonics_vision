#!/usr/bin/env python3

from panda_ros.pose_transform_functions import list_2_quaternion, pos_quat_2_pose_st
from platonics_vision.srv import IterativeRegistrationLocalizer, IterativeRegistrationLocalizerResponse, IterativeRegistrationLocalizerRequest, SavingPointcloudRequest
from sensor_msgs.msg import Image
from panda_ros import Panda
from panda_ros.pose_transform_functions import orientation_2_quaternion, pose_st_2_transformation, transform_pose, transformation_2_pose, pose_2_transformation

import tf
from platonics_vision.srv import SiftRegistrationLocalizerRequest, SiftRegistrationLocalizer, SiftRegistrationLocalizerResponse
import numpy as np

from geometry_msgs.msg import PoseStamped, Pose
from tf.transformations import euler_from_quaternion
from queue import Queue
import rospy
import rospkg
import yaml
import math

class ActiveLocalizerNode():
    def __init__(self) -> None:
        rospy.init_node("iterative_sift_localizer")
        self._rate = rospy.Rate(1)
        self._panda = Panda()
        self.height_offset = 0
        rospack = rospkg.RosPack()
        self._templates_folder = rospack.get_path("platonics_dataset") + "/trajectories/"

        rospy.wait_for_service('sift_localization')
        self.compute_box_tf = rospy.ServiceProxy('sift_localization', SiftRegistrationLocalizer)

        self._iterative_sift_service = rospy.Service('iterative_sift_localizer', IterativeRegistrationLocalizer, self.handle_request)


        self._tf_listener = tf.TransformListener()

        self.position_accuracy = 0.001
        self.orientation_accuracy=0.2 *(np.pi/180)
        self.timeout_counter = 15

    @property
    def height(self) -> float:
        return float(self._params['position']['z'])

    @property
    def home_pose(self) -> PoseStamped:
        home_pose = PoseStamped()
        home_pose.header.frame_id = 'panda_link0'
        home_pose.pose.position.x = float(self._params['position']['x'])
        home_pose.pose.position.y = float(self._params['position']['y'])
        home_pose.pose.position.z = float(self._params['position']['z'])
        home_pose.pose.orientation.x = float(self._params['orientation']['x'])
        home_pose.pose.orientation.y = float(self._params['orientation']['y'])
        home_pose.pose.orientation.z = float(self._params['orientation']['z'])
        home_pose.pose.orientation.w = float(self._params['orientation']['w'])
        return home_pose




    def handle_request(self, req: IterativeRegistrationLocalizer):

        parameter_file = self._templates_folder + req.template_file_name.data + '/template/params.yaml'
        with open(parameter_file) as f:
            self._params = yaml.safe_load(f)

        self._panda.go_to_pose_ik(self.home_pose)
        self._panda.offset_compensator(10)
        rospy.sleep(2.0)

        self._rate.sleep()
        sift_request = SiftRegistrationLocalizerRequest()
        sift_request.template_folder_name = req.template_file_name
        response = IterativeRegistrationLocalizerResponse()

        for i in range(req.steps.data):
            rospy.loginfo(f"Step {i}")
            position = self._panda.curr_pos
            ori = list_2_quaternion(self._panda.curr_ori)
            home_pose = pos_quat_2_pose_st(position, ori)
            try:
                resp = self.compute_box_tf(sift_request)
                box_tf = resp.pose

                ori = [
                    resp.pose.pose.orientation.x,
                    resp.pose.pose.orientation.y,
                    resp.pose.pose.orientation.z,
                    resp.pose.pose.orientation.w
                ]
                xy_yaw = [
                    resp.pose.pose.position.x, 
                    resp.pose.pose.position.y,
                    euler_from_quaternion(ori)[2]
                ]

            except Exception as e:
                rospy.logwarn(e)
                continue
            box_tf.pose.position.z = 0

            
            self._transformed_pose = self.transform_old(box_tf, home_pose)
            self._panda.go_to_pose_ik(self._transformed_pose)
            self._panda.offset_compensator(10)
            rospy.sleep(2.0)
            rospy.loginfo("Finished go to.")
            """
            pos_error = np.linalg.norm(xy_yaw[:2])
            yaw_error = abs(xy_yaw[2])
            print(f"position error {pos_error}, yaw error {yaw_error}")
            if (pos_error < self.position_accuracy and yaw_error < self.orientation_accuracy or self.timeout_counter > self.timeout_counter):
                final_resp.message = f"Finished localization, final error: {pos_error + yaw_error}"
                final_resp.success = True
                print(final_resp.message)
                return final_resp
            self.timeout_counter = self.timeout_counter + 1
            """
        response.success.data = True
        response.pose = self.compute_transform()
        return response
    
    def compute_transform(self) -> Pose:
        transform_new = pose_st_2_transformation(self._panda.curr_pose)
        home_pose_matrix = pose_st_2_transformation(self.home_pose)
        print('transform_new', transform_new)
        print('home pose', home_pose_matrix)
        final_transform =  transform_new @ np.linalg.inv(home_pose_matrix)
        final_transform_projected = self.transform_2d_plane(final_transform, home_pose_matrix)
        """
        final_transform[2,0]=0
        final_transform[0,2]=0
        final_transform[2,1]=0
        final_transform[1,2]=0
        final_transform[2,2]=1
        final_transform[2,3]=0
        """
        final_pose = transformation_2_pose(final_transform)
        return final_pose.pose

    def get_transform(self, source_frame, target_frame):
        while True:
            try:
                now = rospy.Time.now()
                self._tf_listener.waitForTransform(source_frame, target_frame, now, rospy.Duration(4.0))
                rp_tr, rp_rt = self._tf_listener.lookupTransform(source_frame, target_frame, now)
                break
            except Exception as e:
                rospy.logwarn(e)
        transform = np.dot(tf.transformations.translation_matrix(rp_tr), tf.transformations.quaternion_matrix(rp_rt))
        return transform

    def transform(self, box_tf, home_pose):
        tf = pose_st_2_transformation(box_tf)
        return transform_pose(home_pose, tf)
    
    def transform_old(self, transformation_pose, pose):
        transform_base_2_cam = self.get_transform('panda_link0', 'camera_color_optical_frame')
        
        # if transform box is not in camera frame, remove the base_2_cam transforms
        transform_box = pose_st_2_transformation(transformation_pose)



        transform = transform_base_2_cam @ transform_box @ np.linalg.inv(transform_base_2_cam)

        projected_transform = self.transform_2d_plane(transform, pose_st_2_transformation(pose))
        print("transforming", projected_transform)
        pose = transform_pose(pose, projected_transform)
        # pose_quat = orientation_2_quaternion(pose.pose.orientation)

        # Maintain orientation and only apply 'yaw' (rotation around EE z-axis)
        # pose.pose.orientation.z = 0
        # pose.pose.orientation.w = 0
        # new_magnitude = np.sqrt(pose_quat.x * pose_quat.x + pose_quat.y * pose_quat.y)
        # pose_quat.x = pose_quat.x / new_magnitude
        # pose_quat.y = pose_quat.y / new_magnitude
        # pose.pose.orientation.x = pose_quat.x
        # pose.pose.orientation.y = pose_quat.y

        pose.pose.position.z=self.height +self.height_offset
        return pose
    
    def transform_2d_plane(self, T_sift, T_start):
        T_goal = np.dot(T_sift, T_start)
        R_goal_2d = T_goal[0:2, 0:2]
        t_goal_2d = T_goal[0:2, 3]
        R_start_2d = T_start[0:2, 0:2]
        t_start_2d = T_start[0:2, 3]
    
        R = T_sift[0:3, 0:3]
        # get the rotation matrix
        R_euler = R / np.linalg.norm(R)
        # get the rotation angle
        angle = math.atan2(R_euler[1, 0], R_euler[0, 0])
    
        R_diff_2d = np.dot(R_goal_2d, R_start_2d.T)
        R_diff_2d = np.array([
            [math.cos(angle), -math.sin(angle)],
            [math.sin(angle), math.cos(angle)]
        ])
        t_diff = t_goal_2d - np.dot(R_diff_2d, t_start_2d)
        T_end = np.eye(4)
        T_end[0:2, 0:2] = R_diff_2d
        T_end[0:2, 3] = t_diff
        return T_end

if __name__ == '__main__':
    active_localizer_node = ActiveLocalizerNode()
    rospy.spin()
